{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment id:    resource group:  \n"
     ]
    }
   ],
   "source": [
    "# Please replace the configurations below.\n",
    "# config_id: The target configuration to create the deployment. Please create the configuration first.\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(\"env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "deployment_id = env[\"deployment_id\"]\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "print(\"deployment id: \", deployment_id, \" resource group: \", resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate connection to SAP AI Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ai_core_service_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m aic_sk \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai_core_service_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m base_url \u001b[38;5;241m=\u001b[39m aic_sk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserviceurls\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI_API_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/v2/lm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m ai_api_client \u001b[38;5;241m=\u001b[39m AIAPIV2Client(\n\u001b[0;32m      4\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m base_url,\n\u001b[0;32m      5\u001b[0m     auth_url\u001b[38;5;241m=\u001b[39maic_sk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/oauth/token\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     client_id\u001b[38;5;241m=\u001b[39maic_sk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      7\u001b[0m     client_secret\u001b[38;5;241m=\u001b[39maic_sk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientsecret\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m     resource_group\u001b[38;5;241m=\u001b[39mresource_group)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ai_core_service_key'"
     ]
    }
   ],
   "source": [
    "aic_sk = config[\"ai_core_service_key\"]\n",
    "base_url = aic_sk[\"serviceurls\"][\"AI_API_URL\"] + \"/v2/lm\"\n",
    "ai_api_client = AIAPIV2Client(\n",
    "    base_url= base_url,\n",
    "    auth_url=aic_sk[\"url\"] + \"/oauth/token\",\n",
    "    client_id=aic_sk['clientid'],\n",
    "    client_secret=aic_sk['clientsecret'],\n",
    "    resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ai_api_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mai_api_client\u001b[49m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[0;32m      2\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: token,\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai-resource-group\u001b[39m\u001b[38;5;124m'\u001b[39m: resource_group,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ai_api_client' is not defined"
     ]
    }
   ],
   "source": [
    "token = ai_api_client.rest_client.get_token()\n",
    "headers = {\n",
    "        \"Authorization\": token,\n",
    "        'ai-resource-group': resource_group,\n",
    "        \"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check deployment status before inference request\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m deployment_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/deployments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url\u001b[38;5;241m=\u001b[39mdeployment_url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m      4\u001b[0m resp \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_url' is not defined"
     ]
    }
   ],
   "source": [
    "# Check deployment status before inference request\n",
    "deployment_url = f\"{base_url}/deployments/{deployment_id}\"\n",
    "response = requests.get(url=deployment_url, headers=headers)\n",
    "resp = response.json()    \n",
    "status = resp['status']\n",
    "\n",
    "deployment_log_url = f\"{base_url}/deployments/{deployment_id}/logs\"\n",
    "if status == \"RUNNING\":\n",
    "        print(f\"Deployment-{deployment_id} is running. Ready for inference request\")\n",
    "else:\n",
    "        print(f\"Deployment-{deployment_id} status: {status}. Not yet ready for inference request\")\n",
    "        #retrieve deployment logs\n",
    "        #{{apiurl}}/v2/lm/deployments/{{deploymentid}}/logs.\n",
    "\n",
    "        response = requests.get(deployment_log_url, headers=headers)\n",
    "        print('Deployment Logs:\\n', response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull the model into Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ai_api_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#model = \"llama3:8b\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#model = \"mistral:latest\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#model = \"phi3:latest\" \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#model = \"mistral:7b-instruct-q5_K_M\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#model = \"mixtral:8x7b-instruct-v0.1-q4_0\" #Important: please resource plan to infer.l in byom-oss-llm-templates/ollama-template.yaml\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m deployment \u001b[38;5;241m=\u001b[39m \u001b[43mai_api_client\u001b[49m\u001b[38;5;241m.\u001b[39mdeployment\u001b[38;5;241m.\u001b[39mget(deployment_id)\n\u001b[0;32m      9\u001b[0m inference_base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment\u001b[38;5;241m.\u001b[39mdeployment_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m openai_base_url \u001b[38;5;241m=\u001b[39m deployment\u001b[38;5;241m.\u001b[39mdeployment_url\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ai_api_client' is not defined"
     ]
    }
   ],
   "source": [
    "model = \"nomic-embed-text\"\n",
    "#model = \"llama3:8b\"\n",
    "#model = \"mistral:latest\"\n",
    "#model = \"phi3:latest\" \n",
    "#model = \"mistral:7b-instruct-q5_K_M\"\n",
    "#model = \"mixtral:8x7b-instruct-v0.1-q4_0\" #Important: please resource plan to infer.l in byom-oss-llm-templates/ollama-template.yaml\n",
    "\n",
    "deployment = ai_api_client.deployment.get(deployment_id)\n",
    "inference_base_url = f\"{deployment.deployment_url}/v1\"\n",
    "openai_base_url = deployment.deployment_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the model from ollama model repository\n",
    "endpoint = f\"{inference_base_url}/api/pull\"\n",
    "print(endpoint)\n",
    "\n",
    "#let's pull the mistral model from ollama\n",
    "json_data = {  \"name\": model}\n",
    "\n",
    "response = requests.post(endpoint, headers=headers, json=json_data)\n",
    "print('Result:', response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byom_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
